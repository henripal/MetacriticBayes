{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "from string import ascii_lowercase\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LETTERS = '#' + ascii_lowercase\n",
    "BASE_URL = 'http://www.metacritic.com/browse/movies/title/dvd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_soup_from_url(url, attempt=0):\n",
    "    attempt = attempt + 1\n",
    "    time.sleep(int(random.random()*20))\n",
    "    if attempt > 10:\n",
    "        return None\n",
    "    try:\n",
    "        req = urllib.request.Request(url, headers={'User-Agent': 'chrome'})\n",
    "        html = urllib.request.urlopen(req).read()\n",
    "        return BeautifulSoup(html, \"lxml\")\n",
    "    except:\n",
    "        make_soup_from_url(url, attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_soup(letter, page, attempt = 0):\n",
    "    if letter == '#':\n",
    "        url = BASE_URL + \"?page=\" + str(page)\n",
    "    else:\n",
    "        url = BASE_URL + \"/\" + letter + \"?page=\" + str(page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for letter in LETTERS:\n",
    "    print('processing letter: ' + letter + ' ...')\n",
    "    page = 0\n",
    "    while True:\n",
    "        soup = make_soup(letter, page)\n",
    "        \n",
    "        if soup:\n",
    "            results = soup.find_all('tr', {'class': 'summary_row'})\n",
    "            links = [result.find('td', {'class': 'title_wrapper'}).find('a')['href'] for result in results]\n",
    "        else:\n",
    "            links = []\n",
    "        \n",
    "        movie_list = movie_list + links\n",
    "        \n",
    "        if links:\n",
    "            page = page + 1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/movielist_mc', 'wb') as f:\n",
    "    pickle.dump(movie_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping individual pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append('../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INDIV_URL = 'http://www.metacritic.com'\n",
    "TR_FIELDS = ['runtime', 'movie_rating', 'company'] \n",
    "MULTI_TR_FIELDS = ['languages', 'countries', 'genres']\n",
    "import csv\n",
    "import Movies\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/movielist_mc', 'rb') as f:\n",
    "    movie_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# oh, lisp, where art thou\n",
    "def get_name(v):\n",
    "    return [ k for k,v in locals().iteritems() if v is blah][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_write(name, index):\n",
    "    with open('../data/' + name + str(index) + '.csv', 'w') as f:\n",
    "        csv_writer = csv.writer(f)\n",
    "        csv_writer.writerows(eval(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_read(name, index):\n",
    "    result = []\n",
    "    with open('../data/' + name + str(index) + '.csv', 'r') as f:\n",
    "        csv_reader = csv.reader(f)\n",
    "        for row in csv_reader:\n",
    "            result.append(row)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_append(url_id, array, iterable):\n",
    "    try:\n",
    "        if isinstance(iterable, str):\n",
    "            array.append([url_id, iterable])\n",
    "        else:\n",
    "            for item in iterable:\n",
    "                array.append([url_id, item])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting...\n",
      "Finished 8256 out of 8445\n",
      "Finished 8261 out of 8445\n",
      "Finished 8266 out of 8445elf\n",
      "Finished 8271 out of 8445\n",
      "Finished 8276 out of 8445\n",
      "Finished 8281 out of 8445days-30-nights---hollywood-to-the-heartland\n",
      "Finished 8286 out of 8445real-world\n",
      "Finished 8291 out of 8445-never-be-the-same\n",
      "Finished 8296 out of 8445\n",
      "Finished 8301 out of 8445\n",
      "Finished 8306 out of 8445\n",
      "Finished 8311 out of 8445ge-w-bush-and-the-rise-of-the-religious-right-in-america\n",
      "Finished 8316 out of 8445tion\n",
      "Finished 8321 out of 8445\n",
      "Finished 8326 out of 8445n\n",
      "Finished 8331 out of 8445ervous-breakdown\n",
      "Finished 8336 out of 8445\n",
      "Finished 8341 out of 8445\n",
      "Finished 8346 out of 8445\n",
      "Finished 8351 out of 8445\n",
      "Finished 8356 out of 84453\n",
      "Finished 8361 out of 8445\n",
      "Finished 8366 out of 8445\n",
      "Finished 8371 out of 8445rkswar-of-the-underworld\n",
      "Finished 8376 out of 8445\n",
      "Finished 8381 out of 8445\n",
      "Finished 8386 out of 8445\n",
      "Finished 8391 out of 8445-stranger\n",
      "Finished 8396 out of 8445\n",
      "Finished 8401 out of 8445\n",
      "Finished 8406 out of 8445t-i-love\n",
      "Finished 8411 out of 8445\n",
      "Finished 8416 out of 8445osessionau-75116-paris\n",
      "Finished 8421 out of 8445\n",
      "Finished 8426 out of 8445\n",
      "Finished 8431 out of 8445iders-from-mars\n",
      "Finished 8436 out of 8445\n",
      "Finished 8441 out of 8445\n",
      "zus-zoia6\r"
     ]
    }
   ],
   "source": [
    "basics =[]\n",
    "languages = []\n",
    "countries =[]\n",
    "genres = []\n",
    "cast = []\n",
    "director = []\n",
    "producer =[]\n",
    "writer = []\n",
    "reviews = []\n",
    "\n",
    "table_list = ['basics', 'languages', 'countries', 'genres', 'cast', 'director', 'producer', 'writer', 'reviews']\n",
    "\n",
    "print('starting...')\n",
    "start_at = 8254\n",
    "\n",
    "for index, movie in enumerate(movie_list):\n",
    "    if index < start_at:\n",
    "        # don't do anything\n",
    "        continue\n",
    "    elif index == start_at:\n",
    "        # load csvs\n",
    "        for name in table_list:\n",
    "            exec(name + '= my_read(\\'' + name + '\\', 1001)')\n",
    "        continue\n",
    "    \n",
    "    if index%5 == 1:\n",
    "        print('Finished ' + str(index) + ' out of ' + str(len(movie_list)))\n",
    "        for name in table_list:\n",
    "            my_write(name, 1001)\n",
    "        \n",
    "        \n",
    "            \n",
    "    url_id = movie[7:] \n",
    "    print(url_id, end ='\\r')\n",
    "    scraped = Movies.Movie(url_id)\n",
    "    basics.append([url_id, \n",
    "             scraped.title, scraped.metascore, scraped.user_score,\n",
    "             scraped.release_date, scraped.runtime, scraped.movie_rating,\n",
    "             scraped.company, scraped.user_reviews[0], scraped.user_reviews[1],\n",
    "            scraped.user_reviews[2]])\n",
    "    \n",
    "    my_append(url_id, languages, scraped.languages)\n",
    "    my_append(url_id, countries, scraped.countries)\n",
    "    my_append(url_id, genres, scraped.genres)\n",
    "    my_append(url_id, cast, scraped.cast)\n",
    "    my_append(url_id, director, scraped.director)\n",
    "    my_append(url_id, producer, scraped.producer)\n",
    "    my_append(url_id, writer, scraped.writer)\n",
    "    \n",
    "    reviews = reviews + [list((url_id,) + review) for review in scraped.reviews]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name in table_list:\n",
    "    my_write(name, 1001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
